# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EU7cN1tq9cLBKlsrGuqCY2997AmG9p5t

# Configuração
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style('whitegrid')
plt.style.use('seaborn-v0_8-pastel')

file = '/content/drive/Shareddrives/TCC Prodam - IBM/86327_SERVIÇOS SOLICITAVEIS - SP156.XLSX - Aba 1.csv'
df = pd.read_csv(file)

"""# Entendimento Inicial dos Dados (Exploratory Data Analysis - EDA):

Visualizar as primeiras linhas
"""

print("primeiras linas:")
print(df.head())

"""Visualizar as ultimas linhas"""

print("ultimas linhas:")
print(df.tail())

"""Verificar o dataframe"""

print(f"\nO DataFrame possui {df.shape[0]} linhas e {df.shape[1]} colunas.")

print("\nInformações do DataFrame:")
df.info()

"""Verificar tamanho dos textos"""

print("\nResumo das colunas de texto:")
print(df['NOME DA CARTA'].str.len().describe())

"""Verificar dados repetidos"""

print("\nResumo das colunas categóricas:")
print(df.describe(include=['object', 'category']))

"""Nome das colunas

"""

print("\nNomes das colunas:")
print(df.columns.tolist())

"""# Limpeza de Dados (Data Cleaning):

Valores nulos
"""

print("\nContagem de valores ausentes por coluna:")
print(df.isnull().sum())

print("\nPorcentagem de valores ausentes por coluna:")
print((df.isnull().sum() / len(df)) * 100)

"""Remove linhas com nulos em colunas específicas"""

df_sem_nulos_subset = df.dropna(subset=['ST SOLICITACAO'])
df_sem_nulos_subset = df.dropna(subset=['SE PERMITE OBSERVACAO'])
df_sem_nulos_subset = df.dropna(subset=['CRIADO POR'])
df_sem_nulos_subset = df.dropna(subset=['DATA CADASTRO'])
df_sem_nulos_subset = df.dropna(subset=['ATUALIZADO POR'])
df_sem_nulos_subset = df.dropna(subset=['DATA ALTERACAO'])

"""Remove colunas com muitos nulos"""

df = df.drop(columns=['ID FORMULARIO CHECKLIST', 'DE FORMULARIO CHECKLIST', 'DE ORIENTACAO OPERADOR'])
print(df.columns)

"""Prenche colunas com o valor que mais aparece"""

df['ÓRGÃO'].fillna(df['ÓRGÃO'].mode()[0], inplace=True)
df['ÓRGÃO'].fillna(' ', inplace=True)

df['ID FORMULARIO DINAMICO'].fillna(df['ID FORMULARIO DINAMICO'].mode()[0], inplace=True) # mode()[0] para pegar o primeiro valor caso haja empate
df['ID FORMULARIO DINAMICO'].fillna(' ', inplace=True)


df['DE FORMULARIO PESQUISA'].fillna(df['DE FORMULARIO PESQUISA'].mode()[0], inplace=True) # mode()[0] para pegar o primeiro valor caso haja empate
df['DE FORMULARIO PESQUISA'].fillna(' ', inplace=True)

"""Verificação pra limpar linhas duplicadas"""

print(f"\nNúmero de linhas duplicadas: {df.duplicated().sum()}")

"""Função pra limpar texto"""

import nltk
nltk.download('stopwords')

!pip install unidecode

import unidecode

import re
from nltk.corpus import stopwords

stopwords_pt = set(stopwords.words('portuguese'))

def limpar_texto(texto):
    texto = texto.lower()                       # Minusculas
    texto = unidecode.unidecode(texto)          # Remove acentuação
    texto = re.sub(r'[^\w\s]', '', texto)       # Remove pontuação
    palavras = texto.split()
    palavras = [p for p in palavras if p not in stopwords_pt]  # Remove stopwords
    return ' '.join(palavras)

df['NOME DA CARTA'] = df['NOME DA CARTA'].apply(limpar_texto)
df['ÓRGÃO'] = df['ÓRGÃO'].apply(limpar_texto)

"""# Análise Estatística e Visual:

Nuvem de palavras
"""

from wordcloud import WordCloud
import matplotlib.pyplot as plt

texto_tudo = ' '.join(df['NOME DA CARTA'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_tudo)

plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

from collections import Counter

palavras = ' '.join(df['NOME DA CARTA']).split()
contagem = Counter(palavras)
print(contagem.most_common(10))

import seaborn as sns

palavras_comuns = contagem.most_common(10)
df_freq = pd.DataFrame(palavras_comuns, columns=['palavra', 'frequencia'])

sns.barplot(x='frequencia', y='palavra', data=df_freq)
plt.xlabel('Frequência')
plt.ylabel('Palavra')
plt.title('Palavras mais frequentes')
plt.show()

"""Analise de sentimento"""

!pip install googletrans

import asyncio
from textblob import TextBlob
from googletrans import Translator

serviços = df['NOME DA CARTA']
translator = Translator()

async def translate_services(services_list):
    translation_tasks = [translator.translate(c, src='pt', dest='en') for c in services_list]
    translated_results = await asyncio.gather(*translation_tasks)
    return [res.text for res in translated_results]
loop = asyncio.get_event_loop()
if loop.is_running():
    serviços_en = await asyncio.create_task(translate_services(serviços))
else:
    serviços_en = loop.run_until_complete(translate_services(serviços))


# Analyze sentiment
for original, traduzido in zip(serviços, serviços_en):
    blob = TextBlob(traduzido)
    print(f"Comentário: {original}")
    print(f"Sentimento (polarity): {blob.sentiment.polarity}")
    print('-'*40)